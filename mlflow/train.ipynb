{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e19b962-ac6c-4434-a3fa-bae64d614bf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"BASE_MODEL_NAME\", \"\", \"Base model\")\n",
    "dbutils.widgets.text(\"NEW_MODEL_NAME\", \"\", \"Train name\")\n",
    "dbutils.widgets.text(\"EPOCHS\", \"\", \"Train epochs\")\n",
    "dbutils.widgets.text(\"LEARNING_RATE\", \"\", \"Train learning rate\")\n",
    "dbutils.widgets.text(\"DATASET_PATH\", \"\", \"Dataset path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "687724f0-ef74-4ebc-b599-5283569e0451",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q torch transformers datasets peft trl bitsandbytes accelerate tqdm torchvision\n",
    "\n",
    "%restart_python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a54bd59-2bb4-4166-8ff2-18b4817fd060",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "# Get the number of available CPU threads\n",
    "num_threads = os.cpu_count() or multiprocessing.cpu_count()\n",
    "print(f\"Number of available threads: {num_threads}\")\n",
    "\n",
    "# Set the number of threads for OpenMP and MKL\n",
    "os.environ[\"OMP_NUM_THREADS\"] = f\"{num_threads}\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = f\"{num_threads}\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = f\"{num_threads}\"\n",
    "os.environ[\"BLAS_NUM_THREADS\"] = f\"{num_threads}\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Set cache directory\n",
    "CACHE_DIR = \"/tmp/hf_cache\"\n",
    "# os.environ[\"HF_HOME\"] = CACHE_DIR\n",
    "# os.environ[\"HF_DATASETS_CACHE\"] = CACHE_DIR\n",
    "\n",
    "# Model names\n",
    "BASE_MODEL_NAME = dbutils.widgets.get(\"BASE_MODEL_NAME\")\n",
    "NEW_MODEL_NAME = dbutils.widgets.get(\"NEW_MODEL_NAME\")\n",
    "EPOCHS = int(dbutils.widgets.get(\"EPOCHS\"))\n",
    "LEARNING_RATE = float(dbutils.widgets.get(\"LEARNING_RATE\"))\n",
    "\n",
    "DATASET_PATH = dbutils.widgets.get(\"DATASET_PATH\")\n",
    "SAVE_MODEL_PATH = f\"/Volumes/mlops/default/mlops_volume/{NEW_MODEL_NAME}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "388de725-81a0-4508-bf0c-1eb4558f9bf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "VOLUME = \"/Volumes/mlops/default/mlops_volume\"\n",
    "dbutils.fs.cp(DATASET_PATH, VOLUME)\n",
    "\n",
    "LOCAL_PATH = f\"{VOLUME}/{os.path.basename(DATASET_PATH)}\"\n",
    "\n",
    "print(f\"Loading dataset: {LOCAL_PATH}\")\n",
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=LOCAL_PATH,\n",
    "    split=\"train\",\n",
    "    cache_dir=CACHE_DIR\n",
    ")\n",
    "\n",
    "print(f\"Using {len(dataset):,} records for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f7277af-a097-4d77-8e15-6429fb1fb73d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "print(f\"Loading base model: {BASE_MODEL_NAME}\")\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks\")\n",
    "loaded_model_pipeline = mlflow.transformers.load_model(\n",
    "    BASE_MODEL_NAME,\n",
    "    device_map=\"cpu\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "model = loaded_model_pipeline.model\n",
    "tokenizer = loaded_model_pipeline.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66800cd1-abee-4c2d-a862-7800a3a3b5b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def format_instruction(example):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a coding assistant. Your task is to write a Python function that matches the given documentation.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Write a Python function for the following documentation:\\n\\n```python\\n{example['docstring']}\\n```\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": example['code']\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f5d69bb-3431-4a61-95e1-9ecbc89de1c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=4,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "training_arguments = SFTConfig(\n",
    "    output_dir=\"./trainer_progress\",\n",
    "    \n",
    "    # max_steps=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    \n",
    "    optim=\"adamw_torch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    save_steps=20,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    \n",
    "    num_train_epochs=EPOCHS,\n",
    "    gradient_accumulation_steps=1,\n",
    "    weight_decay=0.0,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=1.0,\n",
    "    warmup_ratio=0.0,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    max_seq_length=128,\n",
    "    packing=False,\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=False,\n",
    "    report_to=\"mlflow\",\n",
    "\n",
    "    ddp_find_unused_parameters=False\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    processing_class=tokenizer,\n",
    "    args=training_arguments,\n",
    "    formatting_func=format_instruction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5eca7ca-c4a7-4f4e-a23c-6fd1500bdff9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Launching training...\")\n",
    "trainer.train(resume_from_checkpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48bf0e26-9a28-4f00-96ed-8c55160de07b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Merging adapter weights with the base model...\")\n",
    "merged_model = trainer.model.merge_and_unload()\n",
    "\n",
    "print(\"Saving model...\")\n",
    "merged_model.save_pretrained(SAVE_MODEL_PATH)\n",
    "tokenizer.save_pretrained(SAVE_MODEL_PATH)\n",
    "\n",
    "# Log the model\n",
    "with mlflow.start_run() as run:\n",
    "    model_info = mlflow.transformers.log_model(\n",
    "        transformers_model=SAVE_MODEL_PATH,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=NEW_MODEL_NAME,\n",
    "        task=\"text-generation\"\n",
    "    )\n",
    "\n",
    "model_version = model_info.registered_model_version\n",
    "print(f\"Model successfully registered as '{NEW_MODEL_NAME}' with version: {model_version}\")\n",
    "\n",
    "# Return the model version\n",
    "dbutils.notebook.exit({\"model\": NEW_MODEL_NAME, \"version\": model_version})"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "train",
   "widgets": {
    "BASE_MODEL_NAME": {
     "currentValue": "deepseek-ai/deepseek-coder-1.3b-instruct",
     "nuid": "42066be9-7738-4508-9c99-b77c005b0c8d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Base model",
      "name": "BASE_MODEL_NAME",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "Base model",
      "name": "BASE_MODEL_NAME",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "DATASET_PATH": {
     "currentValue": "",
     "nuid": "b4ed5dd4-c32f-456c-a2c6-0bc1c5df5bd4",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Dataset path",
      "name": "DATASET_PATH",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "Dataset path",
      "name": "DATASET_PATH",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "EPOCHS": {
     "currentValue": "",
     "nuid": "458185da-1637-49bb-a211-eafa19ae2b4f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Train epochs",
      "name": "EPOCHS",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "Train epochs",
      "name": "EPOCHS",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "NEW_MODEL_NAME": {
     "currentValue": "",
     "nuid": "4fd44c86-e918-4352-89ba-36d49bf0c366",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Train name",
      "name": "NEW_MODEL_NAME",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "Train name",
      "name": "NEW_MODEL_NAME",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
